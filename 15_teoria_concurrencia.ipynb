{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6093d1d2",
   "metadata": {},
   "source": [
    "[![imagenes](imagenes/pythonista.png)](https://pythonista.io)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75b2f22f",
   "metadata": {},
   "source": [
    "# Teoría de Concurrencia, Paralelismo y Asincronía\n",
    "\n",
    "Este cuaderno no contiene ejercicios de código para resolver, sino que sirve como una **fundamentación teórica exhaustiva** antes de sumergirnos en los módulos de `threading`, `multiprocessing` y `asyncio`.\n",
    "\n",
    "## 1. Conceptos Fundamentales\n",
    "\n",
    "A menudo usamos \"concurrencia\" y \"paralelismo\" de forma intercambiable, pero en ciencias de la computación son conceptos distintos.\n",
    "\n",
    "### Concurrencia (Concurrency)\n",
    "La capacidad de un sistema para **gestionar** múltiples tareas al mismo tiempo. No implica necesariamente que se estén ejecutando en el mismo instante físico, sino que sus ejecuciones se solapan en un periodo de tiempo. \n",
    "*   **Analogía**: Un chef picando cebolla, poniendo agua a hervir y vigilando el horno. Hace todo \"a la vez\", pero solo una cosa en cada instante preciso.\n",
    "\n",
    "### Paralelismo (Parallelism)\n",
    "La capacidad de **ejecutar** múltiples tareas simultáneamente en el mismo instante físico. Requiere hardware con múltiples núcleos de procesamiento.\n",
    "*   **Analogía**: Tres chefs en la cocina; uno pica cebolla, otro vigila el agua y otro el horno. Todos trabajan en el mismo segundo exacto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dd0346a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import threading\n",
    "import multiprocessing\n",
    "\n",
    "def tarea_simulada(nombre, duracion):\n",
    "    print(f\"Iniciando {nombre}...\")\n",
    "    time.sleep(duracion)\n",
    "    print(f\"Finalizando {nombre}...\")\n",
    "\n",
    "# Esto es ejecución secuencial (ni concurrente ni paralela)\n",
    "start = time.time()\n",
    "tarea_simulada(\"Tarea A\", 1)\n",
    "tarea_simulada(\"Tarea B\", 1)\n",
    "print(f\"Tiempo secuencial: {time.time() - start:.2f}s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aff0a06",
   "metadata": {},
   "source": [
    "## 2. El Runtime de Python y el GIL\n",
    "\n",
    "CPython, la implementación estándar de Python, tiene un mecanismo llamado **Global Interpreter Lock (GIL)**. \n",
    "\n",
    "### ¿Qué es el GIL?\n",
    "Es un semáforo (mutex) que protege el acceso a los objetos de Python, impidiendo que múltiples hilos nativos ejecuten bytecodes de Python simultáneamente en el mismo proceso. \n",
    "\n",
    "### Implicaciones\n",
    "Incluso si tienes un procesador de 64 núcleos y lanzas 64 hilos en Python, **solo uno** podrá ejecutar código Python a la vez. El sistema operativo puede cambiar entre hilos (context switching), dando la ilusión de paralelismo, pero es **concurrencia**.\n",
    "\n",
    "**Excepción importante**: Muchas operaciones de E/S (lectura de archivos, red) y ciertas extensiones en C (como NumPy) liberan el GIL, permitiendo verdadero paralelismo en esas operaciones específicas.\n",
    "\n",
    "> **Novedad en Python 3.13+ (Experimental)**: A partir de la versión 3.13, se ha introducido soporte experimental para ejecutar Python sin el GIL (PEP 703). Esto permite que los hilos de Python se ejecuten en verdadero paralelismo en múltiples núcleos. Sin embargo, esto requiere utilizar una versión del intérprete compilada específicamente en modo \"free-threaded\" y es posible que algunas bibliotecas externas aún no sean compatibles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1cbc198",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cuenta_regresiva(n):\n",
    "    while n > 0:\n",
    "        n -= 1\n",
    "\n",
    "COUNT = 50000000\n",
    "\n",
    "# Prueba secuencial\n",
    "start = time.time()\n",
    "cuenta_regresiva(COUNT)\n",
    "print(f\"Secuencial: {time.time() - start:.4f}s\")\n",
    "\n",
    "# Prueba con Hilos (Threading) - CPU Bound\n",
    "# Debido al GIL, esto NO será más rápido (y a menudo es más lento por el overhead)\n",
    "t1 = threading.Thread(target=cuenta_regresiva, args=(COUNT // 2,))\n",
    "t2 = threading.Thread(target=cuenta_regresiva, args=(COUNT // 2,))\n",
    "\n",
    "start = time.time()\n",
    "t1.start(); t2.start()\n",
    "t1.join(); t2.join()\n",
    "print(f\"Con Hilos (CPU-Bound): {time.time() - start:.4f}s (¡Observa el impacto del GIL!)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6481e24a",
   "metadata": {},
   "source": [
    "## 3. Tipos de Carga: CPU-Bound vs I/O-Bound\n",
    "\n",
    "Para elegir la herramienta correcta, primero debes identificar qué limita tu programa.\n",
    "\n",
    "### I/O-Bound (Limitado por Entrada/Salida)\n",
    "El programa pasa la mayor parte del tiempo esperando: esperando respuesta de red, esperando escritura en disco, esperando input del usuario.\n",
    "*   **Ejemplos**: Web scraping, servidores web, lectura de CSVs gigantes.\n",
    "*   **Solución en Python**: `threading` o `asyncio`. El GIL no molesta aquí porque se libera durante la espera.\n",
    "\n",
    "### CPU-Bound (Limitado por Procesador)\n",
    "El programa pasa la mayor parte del tiempo calculando números.\n",
    "*   **Ejemplos**: Procesamiento de imágenes, entrenamiento de modelos ML, compresión de video.\n",
    "*   **Solución en Python**: `multiprocessing`. Necesitas procesos separados (cada uno con su propio GIL e intérprete) para usar múltiples núcleos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a187987",
   "metadata": {},
   "source": [
    "## 4. Modelos de Ejecución Comparados\n",
    "\n",
    "| Característica | Procesos (`multiprocessing`) | Hilos (`threading`) | Asincronía (`asyncio`) |\n",
    "| :--- | :--- | :--- | :--- |\n",
    "| **Memoria** | Aislada (cada proceso tiene su copia) | Compartida (todos acceden a lo mismo) | Compartida (un solo proceso/hilo) |\n",
    "| **Overhead** | Alto (crear un proceso es costoso) | Medio (context switching del OS) | Muy Bajo (cambio de tarea en userspace) |\n",
    "| **Paralelismo** | Sí (Multi-Core Real) | No (Concurrencia por GIL) | No (Concurrencia en 1 hilo) |\n",
    "| **Uso Ideal** | Tareas CPU-Bound pesadas | Tareas I/O-Bound simples/legacy | Tareas I/O-Bound masivas (10k+ conexiones) |\n",
    "| **Dificultad** | Media (serialización de datos) | Alta (Race conditions, Deadlocks) | Alta (Nuevo paradigma de programación) |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ae0d2bd",
   "metadata": {},
   "source": [
    "## 5. Leyes Teóricas del Rendimiento\n",
    "\n",
    "### Ley de Amdahl\n",
    "Establece el límite teórico de ganancia de velocidad (speedup) que se puede obtener al paralelizar una tarea.\n",
    "\n",
    "$$S_{latencia}(s) = \\frac{1}{(1-p) + \\frac{p}{s}}$$\n",
    "\n",
    "Donde:\n",
    "*   $S$: Speedup total.\n",
    "*   $p$: Proporción del programa que es paralelizable.\n",
    "*   $s$: Número de procesadores (speedup de la parte paralela).\n",
    "\n",
    "**Lección**: Si el 10% de tu programa es secuencial (no paralelizable), el speedup máximo nunca superará 10x, sin importar si usas 1 millón de procesadores."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16ed670b",
   "metadata": {},
   "source": [
    "<p style=\"text-align: center\"><a rel=\"license\" href=\"http://creativecommons.org/licenses/by/4.0/\"><img alt=\"Licencia Creative Commons\" style=\"border-width:0\" src=\"https://i.creativecommons.org/l/by/4.0/80x15.png\" /></a><br />Esta obra está bajo una <a rel=\"license\" href=\"http://creativecommons.org/licenses/by/4.0/\">Licencia Creative Commons Atribución 4.0 Internacional</a>.</p>\n",
    "<p style=\"text-align: center\">&copy; José Luis Chiquete Valdivieso. 2017-2026.</p>"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
